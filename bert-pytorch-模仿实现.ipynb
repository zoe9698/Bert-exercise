{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from random import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    'Hello, how are you? I am Romeo.\\n' # R\n",
    "    'Hello, Romeo My name is Juliet. Nice to meet you.\\n' # J\n",
    "    'Nice meet you too. How are you today?\\n' # R\n",
    "    'Great. My baseball team won the competition.\\n' # J\n",
    "    'Oh Congratulations, Juliet\\n' # R\n",
    "    'Thank you Romeo\\n' # J\n",
    "    'Where are you going today?\\n' # R\n",
    "    'I am going shopping. What about you?\\n' # J\n",
    "    'I am going to visit my grandmother. she is not very well' # R\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉所有句子的标点符号\n",
    "sentences = re.sub(\"[.,?!]\",'',text.lower()).split('\\n')\n",
    "#所有词的列表\n",
    "word_list = list(set(\" \".join(sentences).split()))\n",
    "#生成带索引的词字典，并添加上四种标志词\n",
    "word2idx = {'[PAD]':0,'[CLS]':1,'[SEP]':2,'[MASK]':3}\n",
    "for i,w in enumerate(word_list):\n",
    "    word2idx[w] = i+4\n",
    "# 对换word2idx的key和value->idx2word\n",
    "idx2word = dict(zip(word2idx.values(),word2idx.keys()))\n",
    "# 上面的两个字典的大小\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# token是所有句子的idx表示，每个句子一个list，所有句子组成一个大list\n",
    "token_list = list()\n",
    "for sentence in sentences:\n",
    "    #每句话的idx表示\n",
    "    idx_sentence = [word2idx[s] for s in sentence.split()]\n",
    "    token_list.append(idx_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Parameters\n",
    "\n",
    "# maxlen表示同一个batch中的所有句子都由30个token组成，不够的补PAD\n",
    "# （这里我实现的方式比较粗暴，直接固定所有batch中的所有句子都为30）\n",
    "maxlen = 30\n",
    "batch_size = 6\n",
    "# max_pred表示最多需要预测多少个单词，即BERT中的完形填空任务\n",
    "max_pred = 5 \n",
    "# n_layers表示Encoder Layer的数量\n",
    "n_layers = 6\n",
    "n_heads = 12\n",
    "# d_model表示Token Embeddings、Segment Embeddings、Position Embeddings的维度\n",
    "d_model = 768\n",
    "# d_ff表示Encoder Layer中全连接层的维度\n",
    "d_ff = 768*4 \n",
    "d_k = d_v = 64  # dimension of K(=Q), V\n",
    "# n_segments表示Decoder input由几句话组成\n",
    "n_segments = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data():\n",
    "    batch = []\n",
    "    positive = negative = 0\n",
    "    while positive!=batch_size/2 or negative!=batch_size/2:\n",
    "        #从sentences中随机取两句话的序号\n",
    "        tokens_a_index,tokens_b_index = randrange(len(sentences)),randrange(len(sentences))\n",
    "        #取对应的句子的token（idx_list）\n",
    "        tokens_a,tokens_b = token_list[tokens_a_index],token_list[tokens_b_index]\n",
    "        #将两个句子合并，并且加上开头结尾符号和中间分隔符，得到一个list，此为input_ids\n",
    "        input_ids = [word2idx['[CLS]']] + tokens_a + [word2idx['[SEP]']] + tokens_b + [word2idx['[SEP]']]\n",
    "        #segment_ids表示句子前后顺序\n",
    "        segment_ids = [0]*(1+len(tokens_a)+1)+[1]*(len(tokens_b)+1)\n",
    "        \n",
    "        #n_pred(编码器需要预测的也就是被遮盖住的词的个数)按原文要求取单个训练例子（两个句子结合的句子）长度的15%遮盖住，限定必须小于max_pred\n",
    "        n_pred = min(max_pred,max(1,int(len(input_ids)*0.15)))\n",
    "        #指代了真实单词的位置，也就是可以被mask的单词的位置\n",
    "        cand_masked_pos = [i for i,token in enumerate(input_ids)\n",
    "                         if token!=word2idx['[CLS]'] and token!=word2idx['[SEP]']]\n",
    "        #将这个句子的所有单词的位置都打散\n",
    "        shuffle(cand_masked_pos)\n",
    "        #被遮住的词和被遮住的词的位置\n",
    "        #注：masked_tokens是原词，input_ids中对应位置的是替换后的词\n",
    "        masked_tokens, masked_pos = [],[]\n",
    "        #取前n_pred个词，因为已经打散了，这就相当于随机去了n_pred个\n",
    "        for pos in cand_masked_pos[:n_pred]:\n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            if random()<0.8:#80%的概率-----MASK掉\n",
    "                input_ids[pos] = word2idx['[MASK]']\n",
    "            elif random()>0.9:#10%的概率-----随便替换一个总词典中的一个词\n",
    "                index = randint(4,vocab_size-1)#不能取前四个标志词\n",
    "                input_ids[pos] = index\n",
    "        \n",
    "        #总句子不够长度的位置补[PAD]\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0]*n_pad)\n",
    "        segment_ids.extend([0]*n_pad)\n",
    "        \n",
    "        #前面有写到n_pred<max_pred\n",
    "        #E.g. input_ids = [1,8, 36, 27, 13, 39, 33, 34,2,39, 33, 35, 26, 30, 38, 17, 5, 22, 16, 6, 12,2]\n",
    "        #     (shuffle)cand_maked_pos = [4, 17, 13, 5, 6, 14, 2, 15, 18, 20, 1, 3, 19, 7, 12, 16, 11, 9, 10]\n",
    "        #     len:19  ;  maxlen:30  ;   n_pred = 19*0.15 = 2.85 = 2  ;  max_pred = 5\n",
    "        #     masked_pos:[4,17]  masked_tokens:[13,22]\n",
    "        #     (masked)input_ids:[4->4, 17->4, 13, 5, 6, 14, 2, 15, 18, 20, 1, 3, 19, 7, 12, 16, 11, 9, 10]\n",
    "        #     masked_pos(补零):[4, 17, 0, 0, 0] masked_tokens(补零):[13,22,0,0,0]\n",
    "        if max_pred > n_pred:\n",
    "            n_pad = max_pred - n_pred\n",
    "            masked_tokens.extend([0]*n_pad)\n",
    "            masked_pos.extend([0]*n_pad)\n",
    "        \n",
    "        #tokens_a_index + 1 == tokens_b_index:表示两个句子相邻，是上下文关系\n",
    "        #positive：表示随机抽到的句子对中，两个句子相邻，的次数\n",
    "        #batch的最后一个参数True表示，两个句子相邻\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
    "            negative += 1\n",
    "            \n",
    "    return batch\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = zip(*batch)\n",
    "#转换为torch张量\n",
    "input_ids, segment_ids, masked_tokens, masked_pos, isNext = \\\n",
    "    torch.LongTensor(input_ids),  torch.LongTensor(segment_ids), torch.LongTensor(masked_tokens),\\\n",
    "    torch.LongTensor(masked_pos), torch.LongTensor(isNext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 39, 33, 35,  3, 31, 29, 13,  2,  3, 33, 35, 11, 31, 29, 13,  2,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]),\n",
       " tensor([11, 39,  0,  0,  0]),\n",
       " tensor([4, 9, 0, 0, 0]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0], segment_ids[0], masked_tokens[0], masked_pos[0], isNext[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Data.Dataset):\n",
    "  def __init__(self, input_ids, segment_ids, masked_tokens, masked_pos, isNext):\n",
    "    self.input_ids = input_ids\n",
    "    self.segment_ids = segment_ids\n",
    "    self.masked_tokens = masked_tokens\n",
    "    self.masked_pos = masked_pos\n",
    "    self.isNext = isNext\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.input_ids)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return self.input_ids[idx], self.segment_ids[idx], self.masked_tokens[idx], self.masked_pos[idx], self.isNext[idx]\n",
    "\n",
    "loader = Data.DataLoader(MyDataSet(input_ids, segment_ids, masked_tokens, masked_pos, isNext), batch_size, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "数据预处理部分结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_q(=inputs_idx)扩展成[batch_size,seq_len,seq_len],所有值等于0的变成True，值等于0表示PAD填充的\n",
    "def get_attn_pad_mask(seq_q,seq_k):\n",
    "    batch_size,seq_len = seq_q.size()\n",
    "#     print(batch_size,seq_len)\n",
    "    pad_attn_mask = seq_q.data.eq(0).unsqueeze(1)\n",
    "    return pad_attn_mask.expand(batch_size,seq_len,seq_len)\n",
    "\n",
    "def gelu(x):\n",
    "    return x*0.5*(1.0+torch.erf(x/math.sqrt(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        #定义超参数\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "        self.pos_embed = nn.Embedding(maxlen, d_model)  # position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self,x,seg):     \n",
    "        #input_x：是一个batch=6个句子对，每个句子对的所有词的idx组成一个list，即二维\n",
    "        #input_pos：每个句子对的位置索引list，没有传入，在下面这三行生成\n",
    "        #下面这三行相当于把pos(input)扩展成和input_x,input_segment一样的shape\n",
    "        \n",
    "        #第二维大小=maxlen=30\n",
    "        seq_len = x.size(1)\n",
    "        #取这个batch中所有位置索引[0,1,2...,29]\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        #unsqueeze在第一个维度前增加一个维度，E.g.shape[1,2]->shape[1,1,2]\n",
    "        #expand_as将pos扩展成和x一样的shape\n",
    "        pos = pos.unsqueeze(0).expand_as(x)\n",
    "        \n",
    "        #调用自带的embedding函数，分别对input_x,input_pos,input_seg生成三个embed值，累加\n",
    "        embedding = self.tok_embed(x)+self.pos_embed(pos)+self.seg_embed(seg)\n",
    "        #归一化\n",
    "        return self.norm(embedding)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])\n",
      "tensor([[ 1,  8, 36, 27, 13, 39, 33, 34,  2, 21, 38, 18, 14, 10, 23,  3,  2,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 28, 13, 34,  2,  4, 27, 13, 35, 20,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  4, 27, 13,  3,  3,  2, 21, 38, 18, 14, 10, 23,  7,  2,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 39,  3, 35, 11, 31, 29, 13,  2, 39, 33, 35,  3, 30, 38, 17,  5, 22,\n",
      "         16,  3, 12,  2,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1, 39, 33, 35,  3, 31, 29, 13,  2,  3, 33, 35, 11, 31, 29, 13,  2,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  9,  3, 15,  2, 28, 13, 34,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])\n",
      "tok_embed: tensor([[[ 1.0508,  0.8882, -0.1502,  ...,  0.5531, -1.5352,  0.3716],\n",
      "         [ 1.0744, -0.5514,  0.6560,  ...,  0.0258,  0.7022,  0.5849],\n",
      "         [ 0.0926, -0.2861,  1.1795,  ...,  0.0308, -1.1578,  1.0883],\n",
      "         ...,\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306]],\n",
      "\n",
      "        [[ 1.0508,  0.8882, -0.1502,  ...,  0.5531, -1.5352,  0.3716],\n",
      "         [-0.9989,  0.5180,  0.1157,  ..., -0.8297,  2.6998, -1.2100],\n",
      "         [ 0.3082, -0.3299, -0.6514,  ..., -1.5049, -0.4095, -1.0360],\n",
      "         ...,\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306]],\n",
      "\n",
      "        [[ 1.0508,  0.8882, -0.1502,  ...,  0.5531, -1.5352,  0.3716],\n",
      "         [-0.5397, -1.5306, -0.4956,  ...,  0.3807, -0.7835,  0.5851],\n",
      "         [ 0.1305, -0.8140,  0.0685,  ..., -0.5620, -2.7473,  0.9339],\n",
      "         ...,\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306]],\n",
      "\n",
      "        [[ 1.0508,  0.8882, -0.1502,  ...,  0.5531, -1.5352,  0.3716],\n",
      "         [ 0.2715,  0.4212,  0.9683,  ..., -2.0914,  0.8930,  0.4136],\n",
      "         [ 1.1749,  0.5898,  0.1944,  ...,  0.0066,  0.1317,  0.3819],\n",
      "         ...,\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306]],\n",
      "\n",
      "        [[ 1.0508,  0.8882, -0.1502,  ...,  0.5531, -1.5352,  0.3716],\n",
      "         [ 0.2715,  0.4212,  0.9683,  ..., -2.0914,  0.8930,  0.4136],\n",
      "         [-0.7940, -1.5877,  1.7571,  ...,  1.5970, -1.0351, -0.3452],\n",
      "         ...,\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306]],\n",
      "\n",
      "        [[ 1.0508,  0.8882, -0.1502,  ...,  0.5531, -1.5352,  0.3716],\n",
      "         [-1.3452,  0.6438,  0.0191,  ..., -1.0643, -0.9017,  1.7023],\n",
      "         [ 1.1749,  0.5898,  0.1944,  ...,  0.0066,  0.1317,  0.3819],\n",
      "         ...,\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306],\n",
      "         [ 1.3397, -0.9033, -0.8305,  ...,  0.6032,  2.5893, -0.6306]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "pos_embed: tensor([[[-0.3519, -0.3630,  0.1940,  ..., -0.9543, -0.2785, -0.9951],\n",
      "         [-0.3907,  0.5585, -0.1557,  ..., -0.8186, -1.3208, -0.3956],\n",
      "         [ 1.2517,  1.6272, -0.0085,  ..., -1.1715, -0.3480,  0.2315],\n",
      "         ...,\n",
      "         [-1.6181, -0.7613, -0.4542,  ...,  1.2384,  0.1614, -0.3847],\n",
      "         [ 0.0127,  0.1963, -0.9424,  ..., -0.1128,  0.6704,  0.7696],\n",
      "         [ 0.5699, -1.3133,  0.0793,  ...,  0.9445, -0.1303,  0.6038]],\n",
      "\n",
      "        [[-0.3519, -0.3630,  0.1940,  ..., -0.9543, -0.2785, -0.9951],\n",
      "         [-0.3907,  0.5585, -0.1557,  ..., -0.8186, -1.3208, -0.3956],\n",
      "         [ 1.2517,  1.6272, -0.0085,  ..., -1.1715, -0.3480,  0.2315],\n",
      "         ...,\n",
      "         [-1.6181, -0.7613, -0.4542,  ...,  1.2384,  0.1614, -0.3847],\n",
      "         [ 0.0127,  0.1963, -0.9424,  ..., -0.1128,  0.6704,  0.7696],\n",
      "         [ 0.5699, -1.3133,  0.0793,  ...,  0.9445, -0.1303,  0.6038]],\n",
      "\n",
      "        [[-0.3519, -0.3630,  0.1940,  ..., -0.9543, -0.2785, -0.9951],\n",
      "         [-0.3907,  0.5585, -0.1557,  ..., -0.8186, -1.3208, -0.3956],\n",
      "         [ 1.2517,  1.6272, -0.0085,  ..., -1.1715, -0.3480,  0.2315],\n",
      "         ...,\n",
      "         [-1.6181, -0.7613, -0.4542,  ...,  1.2384,  0.1614, -0.3847],\n",
      "         [ 0.0127,  0.1963, -0.9424,  ..., -0.1128,  0.6704,  0.7696],\n",
      "         [ 0.5699, -1.3133,  0.0793,  ...,  0.9445, -0.1303,  0.6038]],\n",
      "\n",
      "        [[-0.3519, -0.3630,  0.1940,  ..., -0.9543, -0.2785, -0.9951],\n",
      "         [-0.3907,  0.5585, -0.1557,  ..., -0.8186, -1.3208, -0.3956],\n",
      "         [ 1.2517,  1.6272, -0.0085,  ..., -1.1715, -0.3480,  0.2315],\n",
      "         ...,\n",
      "         [-1.6181, -0.7613, -0.4542,  ...,  1.2384,  0.1614, -0.3847],\n",
      "         [ 0.0127,  0.1963, -0.9424,  ..., -0.1128,  0.6704,  0.7696],\n",
      "         [ 0.5699, -1.3133,  0.0793,  ...,  0.9445, -0.1303,  0.6038]],\n",
      "\n",
      "        [[-0.3519, -0.3630,  0.1940,  ..., -0.9543, -0.2785, -0.9951],\n",
      "         [-0.3907,  0.5585, -0.1557,  ..., -0.8186, -1.3208, -0.3956],\n",
      "         [ 1.2517,  1.6272, -0.0085,  ..., -1.1715, -0.3480,  0.2315],\n",
      "         ...,\n",
      "         [-1.6181, -0.7613, -0.4542,  ...,  1.2384,  0.1614, -0.3847],\n",
      "         [ 0.0127,  0.1963, -0.9424,  ..., -0.1128,  0.6704,  0.7696],\n",
      "         [ 0.5699, -1.3133,  0.0793,  ...,  0.9445, -0.1303,  0.6038]],\n",
      "\n",
      "        [[-0.3519, -0.3630,  0.1940,  ..., -0.9543, -0.2785, -0.9951],\n",
      "         [-0.3907,  0.5585, -0.1557,  ..., -0.8186, -1.3208, -0.3956],\n",
      "         [ 1.2517,  1.6272, -0.0085,  ..., -1.1715, -0.3480,  0.2315],\n",
      "         ...,\n",
      "         [-1.6181, -0.7613, -0.4542,  ...,  1.2384,  0.1614, -0.3847],\n",
      "         [ 0.0127,  0.1963, -0.9424,  ..., -0.1128,  0.6704,  0.7696],\n",
      "         [ 0.5699, -1.3133,  0.0793,  ...,  0.9445, -0.1303,  0.6038]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "seg_embed: tensor([[[-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         ...,\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864]],\n",
      "\n",
      "        [[-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         ...,\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864]],\n",
      "\n",
      "        [[-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         ...,\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864]],\n",
      "\n",
      "        [[-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         ...,\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864]],\n",
      "\n",
      "        [[-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         ...,\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864]],\n",
      "\n",
      "        [[-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         ...,\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864],\n",
      "         [-0.1709,  1.4938, -0.3348,  ...,  1.4211, -0.3721, -0.3864]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for input_ids, segment_ids, masked_tokens, masked_pos, isNext in loader:\n",
    "    if i==1:\n",
    "        break\n",
    "#     print(\"input_ids:\",input_ids)\n",
    "#     print(\"\\nsegment_ids:\",segment_ids)\n",
    "#     print(\"\\nmasked_tokens:\",masked_tokens)\n",
    "#     print(\"\\nmasked_pos:\",masked_pos)\n",
    "#     print(\"\\nisNext:\",isNext)\n",
    "    i+=1\n",
    "    \n",
    "    seq_len = input_ids.size(1)#第二维大小=30\n",
    "    pos = torch.arange(seq_len, dtype=torch.long)\n",
    "    print(pos)\n",
    "    print(pos.unsqueeze(0))\n",
    "    print(input_ids)\n",
    "    print(pos.unsqueeze(0).expand_as(input_ids))\n",
    "    \n",
    "    tok_embed = nn.Embedding(vocab_size, d_model)\n",
    "    print(\"tok_embed:\",tok_embed(input_ids))\n",
    "\n",
    "    pos = pos.unsqueeze(0).expand_as(input_ids)\n",
    "    pos_embed = nn.Embedding(maxlen, d_model)\n",
    "    print(\"pos_embed:\",pos_embed(pos))\n",
    "\n",
    "    seg_embed = nn.Embedding(n_segments, d_model)\n",
    "    print(\"seg_embed:\",seg_embed(segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size, n_heads, seq_len, seq_len]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.Model_W_Q = nn.Linear(d_model,d_k * n_heads)\n",
    "        self.Model_W_K = nn.Linear(d_model,d_k * n_heads)#d_k==d_q\n",
    "        self.Model_W_V = nn.Linear(d_model,d_v * n_heads)\n",
    "    \n",
    "    def forward(self,Q,K,V,attn_mask):\n",
    "        #self-attention:Q=K=V\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        \n",
    "        q_s = self.Model_W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size, n_heads, seq_len, d_k]\n",
    "        k_s = self.Model_W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size, n_heads, seq_len, d_k]\n",
    "        v_s = self.Model_W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size, n_heads, seq_len, d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n",
    "\n",
    "        # context: [batch_size, n_heads, seq_len, d_v], attn: [batch_size, n_heads, seq_len, seq_len]\n",
    "        context = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size, seq_len, n_heads, d_v]\n",
    "        output = nn.Linear(n_heads * d_v, d_model)(context)\n",
    "        return nn.LayerNorm(d_model)(output + residual) # output: [batch_size, seq_len, d_model]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model,d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff,d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, d_ff) -> (batch_size, seq_len, d_model)\n",
    "        return self.fc2(gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "    \n",
    "    def forward(self,enc_inputs,enc_self_attn_mask):\n",
    "        enc_outputs = self.enc_self_attn(enc_inputs,enc_inputs,enc_inputs,enc_self_attn_mask)\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, seq_len, d_model]\n",
    "        return enc_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT,self).__init__()\n",
    "        self.embedding = Embedding()\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "        #nn.Sequential(API):一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数。\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model,d_model),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model,2)\n",
    "        self.linear = nn.Linear(d_model,d_model)\n",
    "        self.activ2 = gelu\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        self.fc2 = nn.Linear(d_model,vocab_size,bias=False)\n",
    "        self.fc2.weight = embed_weight\n",
    "    \n",
    "    def forward(self,input_ids,segment_ids,masked_pos):\n",
    "        output = self.embedding(input_ids,segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids,input_ids)\n",
    "        for layer in self.layers:\n",
    "            output = layer(output,enc_self_attn_mask)\n",
    "        \n",
    "        h_pooled = self.fc(output[:, 0]) # [batch_size, d_model]\n",
    "        logits_clsf = self.classifier(h_pooled) # [batch_size, 2] predict isNext\n",
    "\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, d_model) # [batch_size, max_pred, d_model]\n",
    "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
    "        h_masked = self.activ2(self.linear(h_masked)) # [batch_size, max_pred, d_model]\n",
    "        logits_lm = self.fc2(h_masked) # [batch_size, max_pred, vocab_size]\n",
    "        return logits_lm, logits_clsf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "函数，方法，变量准备工作结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0010 loss = 1.374374\n",
      "Epoch: 0020 loss = 1.003074\n",
      "Epoch: 0030 loss = 0.881680\n",
      "Epoch: 0040 loss = 0.843361\n",
      "Epoch: 0050 loss = 0.823525\n",
      "Epoch: 0060 loss = 0.805731\n",
      "Epoch: 0070 loss = 0.837577\n",
      "Epoch: 0080 loss = 0.847171\n",
      "Epoch: 0090 loss = 0.815844\n",
      "Epoch: 0100 loss = 0.822766\n",
      "Epoch: 0110 loss = 0.787375\n",
      "Epoch: 0120 loss = 0.821672\n",
      "Epoch: 0130 loss = 0.818850\n",
      "Epoch: 0140 loss = 0.810293\n",
      "Epoch: 0150 loss = 0.829645\n",
      "Epoch: 0160 loss = 0.795248\n",
      "Epoch: 0170 loss = 0.822731\n",
      "Epoch: 0180 loss = 0.800113\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(180):\n",
    "    for input_ids, segment_ids, masked_tokens, masked_pos, isNext in loader:\n",
    "      logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
    "      loss_lm = criterion(logits_lm.view(-1, vocab_size), masked_tokens.view(-1)) # for masked LM\n",
    "      loss_lm = (loss_lm.float()).mean()\n",
    "      loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
    "      loss = loss_lm + loss_clsf\n",
    "      if (epoch + 1) % 10 == 0:\n",
    "          print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
